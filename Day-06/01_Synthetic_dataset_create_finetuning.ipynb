{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbgUPPfQa40C"
   },
   "source": [
    "# LLM을 활용한 데이터셋 구축\n",
    "\n",
    "최근 대규모 언어 모델(LLM)의 발전으로 고품질의 텍스트 데이터를 프로그래밍 방식으로 생성하는 것이 가능해졌습니다.  \n",
    "이러한 합성 데이터셋(Synthetic Dataset)은 특정 태스크에 맞는 학습 데이터를 구하기 어려운 경우 매우 효과적인 대안이 됩니다.\n",
    "\n",
    "LLM을 활용하여 의도 분류(Intent Classification)를 위한 데이터셋을 자동으로 생성하는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1759140871747,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "nex0FpraPYPo",
    "outputId": "6e1c93a5-726a-4381-955f-5e2113067d83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openrouter_llm import create_openrouter_llm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = model = create_openrouter_llm(\"openai/gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U59ArVCbjI8O"
   },
   "source": [
    "### 데이터 생성 파라미터 정의\n",
    "데이터셋 생성에 필요한 핵심 파라미터를 정의합니다.   \n",
    "MACRO_INTENTS는 생성할 데이터의 최상위 의도(Intent) 카테고리를 목록화한 것입니다.  \n",
    "DEFAULT_ROUTER는 각 의도의 기본 복잡도를 설정하여, 추후 생성될 문장의 suggested_model 레이블을 결정하는 규칙으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1759139344546,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "5oBsBuR1PyAA"
   },
   "outputs": [],
   "source": [
    "# --- 사용자 정의: Macro-Intent 목록 ---\n",
    "MACRO_INTENTS = [\n",
    "    \"계정_관리\",  # 계정 생성/로그인/비밀번호 등\n",
    "    \"주문_결제\",  # 주문, 결제 수단, 결제 실패\n",
    "    \"배송_문의\",  # 배송상태, 배송기간, 추적\n",
    "    \"상품_정보\",  # 상품 상세, 재고, 옵션\n",
    "    \"기술_지원\",  # 오류, 기능문의, 사용법\n",
    "    \"반품_환불\",  # 반품절차, 환불요청\n",
    "]\n",
    "\n",
    "# 라우팅 기준: simple -> small model, complex -> large model\n",
    "# 여기서는 각 Intent에 대해 기본 권장 모델을 지정할 수 있습니다.\n",
    "DEFAULT_ROUTER = {\n",
    "    # Intent: \"simple_by_default\" (True면 일반적으로 아주 작은 소형모델(2B 이하)로 처리 가능)\n",
    "    \"계정_관리\": True,\n",
    "    \"주문_결제\": False,\n",
    "    \"배송_문의\": True,\n",
    "    \"상품_정보\": True,\n",
    "    \"기술_지원\": False,\n",
    "    \"반품_환불\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0n-MafpjLrL"
   },
   "source": [
    "### LLM을 이용한 발화(Utterance) 데이터 생성 함수\n",
    "LLM을 호출하여 특정 의도(Intent)에 해당하는 예시 문장들을 생성하는 함수 llm_generate_utterances를 정의합니다.  \n",
    "이 함수는 LLM에게 JSON 배열 형식으로 응답을 요청하는 프롬프트를 구성하고, 반환된 텍스트를 파싱하여 {'text': ..., 'complexity': ...} 형태의 딕셔너리 리스트로 반환합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759139346733,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "EecQ6zElP037"
   },
   "outputs": [],
   "source": [
    "async def llm_generate_utterances(intent: str, n: int = 100) -> list[dict]:\n",
    "    \"\"\"\n",
    "    LLM을 사용해 intent별로 예문을 생성합니다.\n",
    "    반환 형식: List of dicts: {\"text\":..., \"complexity\": \"simple\"/\"complex\"}\n",
    "    프롬프트는 LLM에게 JSONL 형식으로 결과를 달라고 요청합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # \"아래의 Parsing을 통과할 수 있도록, 주어진 \"형식\"에 집중하여 프롬프팅 해주세요.\n",
    "    # 예시는 답이 될 수 있는 하나일 뿐이고, 구동 시 확인하실 수 있다시피 이 답 또한 생성 성공 100%를 보장하지 않습니다.\n",
    "    # 만족하실만한 결과물이 나온다면 충분합니다.\n",
    "    prompt = (\n",
    "        f\"\"\"다음은 사용자와의 대화 중 대주제 '{intent}'에 해당하는 실제 사용자가 말할 법한 예시 문장 {n} 개를 JSON 배열로 생성해 주세요. \n",
    "        각 항목은 'text'와 'complexity' 필드를 가지며 'complexity'는 'simple' 또는 'complex' 중 하나로 표기하세요.\n",
    "        \n",
    "        [예시 데이터]\n",
    "        [{\"text\": \"...\", \"complexity\": \"simple\"}, ...]'\n",
    "        \n",
    "        [주의사항]\n",
    "        제공된 형식에 어긋나는 답변은 하지 않도록 유의해주세요.\n",
    "        \"\"\"\n",
    "    )\n",
    "    try:\n",
    "        result = await llm.ainvoke(prompt)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Local 에서 진행합니다.\n",
    "# Question: LLM에서 출력된 데이터를 어떻게 정리해야할까요? 아래의 코드 구조와 프롬프트를 자세히 살펴보고 고민해서 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8mK5sLgjS8k"
   },
   "source": [
    "### 추천 모델 할당 로직 정의\n",
    "생성된 문장의 의도와 복잡도를 기반으로 small 또는 large 모델을 추천하는 로직을 함수로 정의합니다. 이 함수는 DEFAULT_ROUTER 규칙을 참조하여, 복잡도가 complex인 경우는 항상 large 모델을, 그렇지 않은 경우는 기본 설정에 따라 모델을 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759139357896,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "XBxAxlvLQK24"
   },
   "outputs": [],
   "source": [
    "# 문제 2: 문장의 의도(intent)와 복잡도(complexity)에 따라 추천 모델('small' 또는 'large')을 할당하는 로직을 구현합니다.\n",
    "# 'complexity'가 'complex'이면 항상 'large'를 반환해야 합니다.\n",
    "# 그렇지 않은 경우, DEFAULT_ROUTER 딕셔너리를 참조하여 모델을 결정합니다.\n",
    "\n",
    "def assign_suggested_model(intent: str, complexity: str) -> str:\n",
    "    \"\"\"기본 라우팅 규칙에 따라 suggested_model을 결정합니다.\"\"\"\n",
    "    base_small = DEFAULT_ROUTER.get(intent, True)\n",
    "    # 복잡한 문장은 대형 모델 권장\n",
    "    if complexity == \"complex\":\n",
    "        return \"large\"\n",
    "    return \"small\" if base_small else \"large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-n0Cfz8jVDb"
   },
   "source": [
    "---\n",
    "\n",
    "### 전체 데이터셋 구축 파이프라인\n",
    "앞서 정의한 함수들을 조합하여 전체 합성 데이터셋을 구축하는 build_dataset 함수를 정의합니다.  \n",
    "이 함수는 정의된 모든 MACRO_INTENTS에 대해 반복적으로 llm_generate_utterances를 호출하고, 각 결과에 assign_suggested_model을 적용하여 최종 레코드를 생성합니다.  \n",
    "생성된 데이터는 중복 제거 후 CSV 및 JSONL 파일 형식으로 저장됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1759141420394,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "lfHU026TQOhC"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv, json\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    intents: list[str], per_intent: int = 100, batch_size: int = 10, out_dir: str = \"output_dataset\"\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    intents: 생성할 intent 목록\n",
    "    per_intent: intent당 최종 생성 개수\n",
    "    batch_size: 한 번에 LLM에 요청할 문장 수\n",
    "    out_dir: 저장 폴더\n",
    "    \"\"\"\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    records = []\n",
    "\n",
    "    for intent in intents:\n",
    "        print(f\"Generating for intent: {intent} (target count={per_intent})\")\n",
    "        generated_count = 0\n",
    "        while generated_count < per_intent:\n",
    "            current_batch = min(batch_size, per_intent - generated_count)\n",
    "            examples = llm_generate_utterances(intent, n=current_batch)\n",
    "            for ex in examples:\n",
    "                text = ex.get(\"text\")\n",
    "                complexity = ex.get(\"complexity\", \"simple\")\n",
    "                suggested_model = assign_suggested_model(intent, complexity)\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"intent\": intent,\n",
    "                        \"text\": text,\n",
    "                        \"complexity\": complexity,\n",
    "                        \"suggested_model\": suggested_model,\n",
    "                    }\n",
    "                )\n",
    "            generated_count += current_batch\n",
    "            print(f\"  Generated so far: {generated_count}/{per_intent}\")\n",
    "\n",
    "    # 중복 제거\n",
    "    unique_texts = set()\n",
    "    deduped = []\n",
    "    for r in records:\n",
    "        key = (r[\"intent\"], r[\"text\"])\n",
    "        if key not in unique_texts:\n",
    "            unique_texts.add(key)\n",
    "            deduped.append(r)\n",
    "\n",
    "    # 저장: CSV 및 JSONL\n",
    "    csv_file = out_path / \"intent_dataset.csv\"\n",
    "    jsonl_file = out_path / \"intent_dataset.jsonl\"\n",
    "\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"intent\", \"text\", \"complexity\", \"suggested_model\"])\n",
    "        writer.writeheader()\n",
    "        for r in deduped:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in deduped:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"Saved {len(deduped)} examples -> {csv_file}, {jsonl_file}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weW8qlMvjX9F"
   },
   "source": [
    "### 데이터셋 생성 실행\n",
    "정의된 build_dataset 함수를 실행하여 실제 데이터셋 생성을 시작합니다. PER_INTENT 변수는 각 의도당 생성할 문장의 수를 지정합니다. 파일이 이미 존재하는 경우, 생성 과정을 건너뛰도록 조건문이 설정되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167862,
     "status": "ok",
     "timestamp": 1759139530980,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "M_qIAnijQQbY",
    "outputId": "0afe65aa-bdef-47f8-f03a-5c2d035f0fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating for intent: 계정_관리 (target count=100)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'coroutine' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# if certain path exists\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33m\"\u001b[39m\u001b[33m./intent_dataset.csv\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_intent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPER_INTENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mbuild_dataset\u001b[39m\u001b[34m(intents, per_intent, batch_size, out_dir)\u001b[39m\n\u001b[32m     22\u001b[39m current_batch = \u001b[38;5;28mmin\u001b[39m(batch_size, per_intent - generated_count)\n\u001b[32m     23\u001b[39m examples = llm_generate_utterances(intent, n=current_batch)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomplexity\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcomplexity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msimple\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'coroutine' object is not iterable"
     ]
    }
   ],
   "source": [
    "INTENTS = MACRO_INTENTS\n",
    "PER_INTENT = 100\n",
    "OUT_DIR = \"./\"\n",
    "# if certain path exists\n",
    "if not os.path.exists(\"./intent_dataset.csv\"):\n",
    "    build_dataset(INTENTS, per_intent=PER_INTENT, out_dir=OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dp7Ji_qWjaGi"
   },
   "source": [
    "### 생성된 데이터 확인\n",
    "생성된 CSV 파일을 pandas DataFrame으로 로드하여 상위 10개 행을 출력하고, 총 데이터 수를 확인합니다. 이를 통해 데이터가 의도한 형식과 내용으로 정상적으로 생성되었는지 검증합니다. 또한, JSONL 파일의 내용도 일부 출력하여 형식을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1759139531046,
     "user": {
      "displayName": "HyunJun Jeon (Rascal)",
      "userId": "00005170878705941810"
     },
     "user_tz": -540
    },
    "id": "An8ZOHb-Q4zP",
    "outputId": "001657b1-f05d-4eb2-f2b1-bf0e8149bfc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 존재 여부: False\n"
     ]
    }
   ],
   "source": [
    "# 셀 5: 생성된 CSV/JSONL 파일을 확인하고 간단히 미리보기\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"intent_dataset.csv\"\n",
    "jsonl_path = \"intent_dataset.jsonl\"\n",
    "\n",
    "\n",
    "print(\"CSV 존재 여부:\", bool(pd.io.common.file_exists(csv_path)))\n",
    "if pd.io.common.file_exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    display(df.head(10))\n",
    "    print(\"총 행 수:\", len(df))\n",
    "\n",
    "# JSONL도 확인\n",
    "if pd.io.common.file_exists(jsonl_path):\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    print(\"JSONL 샘플 (최초 5줄):\")\n",
    "    print(\"\".join(lines[:5]))\n",
    "    print(\"총 JSONL 라인 수:\", len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0kVr-MOjhCO"
   },
   "source": [
    "### 데이터셋 로컬 다운로드\n",
    "\n",
    "생성된 데이터셋 파일(intent_dataset.csv, intent_dataset.jsonl)을 로컬 머신으로 다운로드하는 코드입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "FxP-l1y5RATi",
    "outputId": "bc36a21d-6358-4ecd-813d-2a52a4ca73c1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 파일 복사\n",
    "csv_path = \"intent_dataset.csv\"\n",
    "jsonl_path = \"intent_dataset.jsonl\"\n",
    "\n",
    "save_dataset_path = \"./\"\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    shutil.copy(csv_path, save_dataset_path)\n",
    "    print(f\"Copied {csv_path} to {save_dataset_path}\")\n",
    "\n",
    "if os.path.exists(jsonl_path):\n",
    "    shutil.copy(jsonl_path, save_dataset_path)\n",
    "    print(f\"Copied {jsonl_path} to {save_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 파인튜닝을 위한 Huggingface Dataset 활용법 - 데이터 전처리 파이프라인\n",
    "\n",
    "> Unsloth 환경을 사용하기 때문에, RunPod 에서 진행해야합니다!\n",
    "\n",
    "\n",
    "1. **원천 로딩 (`01_data_preparation.ipynb`)** – `wicho/kor_3i4k` train/test split을 불러오고 레이블(0-6)을 의도명과 매핑합니다.\n",
    "2. **Instruction 변환** – `kor3i4k_to_sharegpt` 함수로 \"human/assistant\" 턴 2개짜리 ShareGPT 포맷을 생성하고, 답변에는 의도 라벨 텍스트만 남깁니다.\n",
    "3. **Harmony 포맷 표준화** – `standardize_sharegpt` + `tokenizer.apply_chat_template()`로 GPT-OSS Harmony 템플릿을 적용하고 `<|channel|>final` 토큰을 덧붙여 추론 시스템과 호환시킵니다.\n",
    "4. **데이터 검증** – 템플릿이 올바르게 적용됐는지 샘플 텍스트를 출력하고, 토큰 길이/레이블 누락 여부를 스크립트로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_ds = load_dataset(\"wicho/kor_3i4k\", split=\"train\")\n",
    "\n",
    "# ClassLabel 이면 names가 있고, 아니면 그냥 None\n",
    "label_feature = raw_ds.features[\"label\"]\n",
    "if hasattr(label_feature, \"names\"):\n",
    "    id2label = {i: name for i, name in enumerate(label_feature.names)}\n",
    "else:\n",
    "    # 혹시 ClassLabel이 아니라면, 그냥 str로 캐스팅\n",
    "    id2label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 GPT-OSS 프롬프트 형식에 맞추기 위해 커스텀 템플릿을 적용합니다.  \n",
    "GPT-OSS의 독특한 특징은 OpenAI [Harmony](https://github.com/openai/harmony) 포맷을 사용한다는 점입니다.   \n",
    "Harmony는 대화 구조, 추론 출력(reasoning output), 도구 호출(tool calling)을 지원합니다.\n",
    "\n",
    "#### Harmony 템플릿 검증\n",
    "데이터셋에 `<|start|>system`, `<|start|>user`, `<|start|>assistant<|channel|>final<|message|>`, `<|return|>` 토큰이 모두 포함되어 있는지, 의도 라벨이 누락되지 않았는지 간단히 검사합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmony 템플릿/레이블 검증\n",
    "from collections import Counter\n",
    "\n",
    "REQUIRED_TOKENS = [\n",
    "    \"<|start|>system\",\n",
    "    \"<|start|>user<|message|>\",\n",
    "    \"<|start|>assistant<|channel|>final<|message|>\",\n",
    "    \"<|return|>\",\n",
    "]\n",
    "\n",
    "issues = []\n",
    "intent_counter = Counter()\n",
    "\n",
    "for idx, example in enumerate(dataset):\n",
    "    text = example[\"text\"]\n",
    "    for token in REQUIRED_TOKENS:\n",
    "        if token not in text:\n",
    "            issues.append((idx, f\"missing token: {token}\"))\n",
    "            break\n",
    "    # 의도 라벨 유무 확인 (assistant 응답 끝에 위치)\n",
    "    intent_text = text.split(\"<|start|>assistant<|channel|>final<|message|>\")[-1]\n",
    "    label = intent_text.replace(\"<|return|>\", \"\").strip()\n",
    "    if not label:\n",
    "        issues.append((idx, \"missing intent label\"))\n",
    "    else:\n",
    "        intent_counter[label] += 1\n",
    "\n",
    "print(f\"검증 완료: 총 {len(dataset)}개 샘플\")\n",
    "print(f\"의도 분포 상위 5개: {intent_counter.most_common(5)}\")\n",
    "if issues:\n",
    "    print(f\"발견된 이슈 {len(issues)}건 (최초 5개): {issues[:5]}\")\n",
    "else:\n",
    "    print(\"모든 샘플이 요구 토큰과 의도 라벨을 포함합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kor3i4k_to_sharegpt(examples):\n",
    "    convos = []\n",
    "\n",
    "    for text, label in zip(examples[\"text\"], examples[\"label\"], strict=False):\n",
    "        if id2label is not None:\n",
    "            label_str = id2label[int(label)]\n",
    "        else:\n",
    "            label_str = str(label)\n",
    "\n",
    "        # 필요하면 kor_3i4k 전체 label 목록도 instruction에 넣을 수 있음\n",
    "        # 여기선 간단히 \"label_str만 출력하라\"고 강하게 제한\n",
    "        user_msg = (\n",
    "            \"다음 한국어 발화의 화자 의도(label)를 분류해 주세요.\\n\"\n",
    "            \"정답으로는 해당 label 이름만 한 단어로 출력하세요.\\n\\n\"\n",
    "            f\"발화: {text}\"\n",
    "        )\n",
    "\n",
    "        assistant_msg = label_str\n",
    "\n",
    "        convos.append(\n",
    "            [\n",
    "                {\"from\": \"human\", \"value\": user_msg},\n",
    "                {\"from\": \"gpt\", \"value\": assistant_msg},\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return {\"conversations\": convos}\n",
    "\n",
    "\n",
    "sharegpt_ds = raw_ds.map(\n",
    "    kor3i4k_to_sharegpt,\n",
    "    batched=True,\n",
    "    remove_columns=raw_ds.column_names,  # text/label 제거하고 conversations만 남길지 선택\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "\n",
    "dataset = standardize_sharegpt(sharegpt_ds)\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) # 이 부분은 당장 데이터 로드가 어려운데, 어떻게 해결해볼 수 있을까요?\n",
    "        for convo in convos\n",
    "    ]\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_channel_final(examples):\n",
    "    fixed_texts = []\n",
    "    for text in examples[\"text\"]:\n",
    "        fixed_texts.append(\n",
    "            text.replace(\n",
    "                \"<|start|>assistant<|message|>\",\n",
    "                \"<|start|>assistant<|channel|>final<|message|>\",\n",
    "            )\n",
    "        )\n",
    "    return {\"text\": fixed_texts}\n",
    "\n",
    "\n",
    "# 이미 채널 태그가 있으면 중복으로 안 바꾸도록 한 번만 체크\n",
    "if \"<|channel|>final\" not in dataset[0][\"text\"]:\n",
    "    dataset = dataset.map(add_channel_final, batched=True)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 확인하고 첫 번째 예시가 어떻게 구성되었는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RunPod 환경에서 진행!\n",
    "# 1) 데이터셋을 로컬에 저장\n",
    "# 2) datasets 라이브러리를 통해서 로컬에 저장한 데이터를 로드해주세요."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langgraph-advanced-tutorial (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01372386bcb64c7ca7cb0250efb6d048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "137db5f66565404e9e500f5958824b03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1528716cabb94484adf936d3130c0e68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_413f3330fe0a4cdc883c2befd997ca46",
       "IPY_MODEL_5937c8e4438e44b0a5998c902403a473",
       "IPY_MODEL_e4f58358e37645c68d8a7b2ca400804e"
      ],
      "layout": "IPY_MODEL_801f186d53154b848963b286982c7831"
     }
    },
    "15839905b67f41f1b289968fccb491b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_137db5f66565404e9e500f5958824b03",
      "placeholder": "​",
      "style": "IPY_MODEL_98118f4274794243843d660ff5ba96a4",
      "value": " 861/861 [00:00&lt;00:00, 31.6kB/s]"
     }
    },
    "1c828553dfa140478016a00b43252e98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e1de41966764dcfbc26b54cb3fa1f6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "413f3330fe0a4cdc883c2befd997ca46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77f72dfccafc4922bbaddac9dd0614c7",
      "placeholder": "​",
      "style": "IPY_MODEL_01372386bcb64c7ca7cb0250efb6d048",
      "value": "model.safetensors: 100%"
     }
    },
    "430e3f8e4e5d4f0095e0164a2a4fa02e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c6cd6484b35499f8afca412cf319926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_adaf575517b442deb6dad21487d48210",
       "IPY_MODEL_98ec6aaf8df34244b9f6ecbc636a857f",
       "IPY_MODEL_15839905b67f41f1b289968fccb491b7"
      ],
      "layout": "IPY_MODEL_2e1de41966764dcfbc26b54cb3fa1f6c"
     }
    },
    "5937c8e4438e44b0a5998c902403a473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe05fc7dbded4f19a577a507ef932cd0",
      "max": 269060552,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b70ac4e0812f4c028776d1b62166b4ce",
      "value": 269060552
     }
    },
    "74515c56bd1e4ead93f8678b990569d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77f72dfccafc4922bbaddac9dd0614c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "801f186d53154b848963b286982c7831": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98118f4274794243843d660ff5ba96a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98ec6aaf8df34244b9f6ecbc636a857f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430e3f8e4e5d4f0095e0164a2a4fa02e",
      "max": 861,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e8e5161f4304f3c9dbe02161d23f00b",
      "value": 861
     }
    },
    "9e8e5161f4304f3c9dbe02161d23f00b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "adaf575517b442deb6dad21487d48210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf00eb93824449588e2ec1dd0efff293",
      "placeholder": "​",
      "style": "IPY_MODEL_b3a03f6cdfb04f02900f893cf00172a5",
      "value": "config.json: 100%"
     }
    },
    "b3a03f6cdfb04f02900f893cf00172a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b70ac4e0812f4c028776d1b62166b4ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf00eb93824449588e2ec1dd0efff293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4f58358e37645c68d8a7b2ca400804e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c828553dfa140478016a00b43252e98",
      "placeholder": "​",
      "style": "IPY_MODEL_74515c56bd1e4ead93f8678b990569d3",
      "value": " 269M/269M [00:05&lt;00:00, 62.0MB/s]"
     }
    },
    "fe05fc7dbded4f19a577a507ef932cd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
