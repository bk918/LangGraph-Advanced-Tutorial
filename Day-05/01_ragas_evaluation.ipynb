{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGAS Evaluation\n",
    "\n",
    "## 참고 자료\n",
    "\n",
    "- RAGAS 공식 문서: https://docs.ragas.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_tavily import TavilySearch\n",
    "from openrouter_llm import create_embedding_model, create_openrouter_llm\n",
    "from ragas import EvaluationDataset, SingleTurnSample, evaluate\n",
    "from ragas.metrics import answer_relevancy, context_precision, context_recall, faithfulness\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = model = create_openrouter_llm(\"openai/gpt-4.1\", temperature=0)\n",
    "embeddings = create_embedding_model(\"openai/text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 평가 데이터 준비\n",
    "\n",
    "샘플 데이터를 생성하거나 기존 데이터를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAG 시스템에서 Retriever의 역할은 무엇인가요?</td>\n",
       "      <td>Retriever는 벡터 데이터베이스에서 질문과 관련된 문서를 검색하여 제공하는 컴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LangChain의 주요 장점은 무엇인가요?</td>\n",
       "      <td>LangChain의 주요 장점은 다양한 LLM과 도구들을 손쉽게 연결하고 체인으로 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embedding 모델의 차원은 무엇을 의미하나요?</td>\n",
       "      <td>차원은 벡터의 크기를 나타내며, 높을수록 의미를 더 정밀하게 표현하지만 메모리와 계...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          question  \\\n",
       "0  RAG 시스템에서 Retriever의 역할은 무엇인가요?   \n",
       "1         LangChain의 주요 장점은 무엇인가요?   \n",
       "2     Embedding 모델의 차원은 무엇을 의미하나요?   \n",
       "\n",
       "                                              answer  \n",
       "0  Retriever는 벡터 데이터베이스에서 질문과 관련된 문서를 검색하여 제공하는 컴...  \n",
       "1  LangChain의 주요 장점은 다양한 LLM과 도구들을 손쉽게 연결하고 체인으로 ...  \n",
       "2  차원은 벡터의 크기를 나타내며, 높을수록 의미를 더 정밀하게 표현하지만 메모리와 계...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 데이터 생성\n",
    "sample_data = [\n",
    "    {\n",
    "        \"question\": \"RAG 시스템에서 Retriever의 역할은 무엇인가요?\",\n",
    "        \"ground_truth\": \"Retriever는 사용자의 질문에 관련된 문서를 벡터 데이터베이스에서 검색하여 가져오는 역할을 합니다.\",\n",
    "        \"contexts\": [\n",
    "            \"RAG 시스템의 Retriever 컴포넌트는 질문과 관련된 문서를 벡터 DB에서 찾아 반환합니다.\",\n",
    "            \"벡터 검색은 임베딩 모델을 사용하여 의미적 유사도를 계산합니다.\",\n",
    "        ],\n",
    "        \"answer\": \"Retriever는 벡터 데이터베이스에서 질문과 관련된 문서를 검색하여 제공하는 컴포넌트입니다.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"LangChain의 주요 장점은 무엇인가요?\",\n",
    "        \"ground_truth\": \"LangChain은 LLM 애플리케이션 개발을 위한 통합 프레임워크로, 다양한 LLM과 툴을 쉽게 연결할 수 있습니다.\",\n",
    "        \"contexts\": [\n",
    "            \"LangChain은 여러 LLM 프로바이더를 통합하여 사용할 수 있는 프레임워크입니다.\",\n",
    "            \"최근 LangChain 은 버전이 1.0 이 되면서 많은 패러다임의 변화를 거치게 되었습니다.\",\n",
    "        ],\n",
    "        \"answer\": \"LangChain의 주요 장점은 다양한 LLM과 도구들을 손쉽게 연결하고 체인으로 구성할 수 있다는 점입니다.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Embedding 모델의 차원은 무엇을 의미하나요?\",\n",
    "        \"ground_truth\": \"Embedding 차원은 텍스트를 벡터로 변환할 때의 벡터 크기를 의미하며, 일반적으로 높을수록 표현력이 좋지만 계산 비용이 증가합니다.\",\n",
    "        \"contexts\": [\n",
    "            \"Embedding 차원이 높으면 더 세밀한 의미를 표현할 수 있습니다.\",\n",
    "            \"OpenAI의 text-embedding-3-large는 3072 차원을 사용합니다.\",\n",
    "        ],\n",
    "        \"answer\": \"차원은 벡터의 크기를 나타내며, 높을수록 의미를 더 정밀하게 표현하지만 메모리와 계산 비용이 늘어납니다.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "pd.DataFrame(sample_data)[[\"question\", \"answer\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리\n",
    "\n",
    "RAGAS 평가를 위해 contexts를 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본: 2개\n",
      "정규화 후: 2개\n",
      "\n",
      "첫 번째 컨텍스트: RAG 시스템의 Retriever 컴포넌트는 질문과 관련된 문서를 벡터 DB에서 찾아 반환...\n"
     ]
    }
   ],
   "source": [
    "def normalize_contexts(contexts: Any) -> list[str]:\n",
    "    \"\"\"컨텍스트 정규화 (dict list → str list)\"\"\"\n",
    "    if not contexts:\n",
    "        return []\n",
    "\n",
    "    normalized = []\n",
    "    for ctx in contexts:\n",
    "        if isinstance(ctx, str):\n",
    "            normalized.append(ctx)\n",
    "        elif isinstance(ctx, dict):\n",
    "            text = ctx.get(\"text\") or ctx.get(\"preview\") or \"\"\n",
    "            if text:\n",
    "                normalized.append(text)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "# 정규화 테스트\n",
    "test_contexts = sample_data[0][\"contexts\"]\n",
    "normalized = normalize_contexts(test_contexts)\n",
    "print(f\"원본: {len(test_contexts)}개\")\n",
    "print(f\"정규화 후: {len(normalized)}개\")\n",
    "print(f\"\\n첫 번째 컨텍스트: {normalized[0][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. WebSearch 통합 (실시간 컨텍스트 수집)\n",
    "\n",
    "**목표**: Tavily/DuckDuckGo를 사용하여 실시간으로 웹에서 정보를 검색하고 RAG 파이프라인을 구축합니다.\n",
    "\n",
    "**파이프라인**:\n",
    "1. 사용자 질문 입력\n",
    "2. WebSearch로 관련 컨텍스트 수집 (Tavily → DuckDuckGo fallback)\n",
    "3. LLM으로 답변 생성\n",
    "4. RAGAS로 평가\n",
    "\n",
    "**커리큘럼 대응**: #1 목적에 맞는 Evaluation Dataset 구축, #2 RAGAS 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_raw_content=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_fallback(query: str, max_results: int = 5) -> list[str]:\n",
    "    \"\"\"Tavily → DuckDuckGo Fallback 검색\n",
    "\n",
    "    Args:\n",
    "        query: 검색 쿼리\n",
    "        max_results: 최대 결과 수\n",
    "\n",
    "    Returns:\n",
    "        검색된 컨텍스트 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Tavily 시도\n",
    "    if tavily_tool:\n",
    "        try:\n",
    "            results = tavily_tool.invoke({\"query\": query})\n",
    "            contexts = [r for r in results]\n",
    "\n",
    "            if contexts:\n",
    "                return contexts[:max_results]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Tavily 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS 평가 파이프라인 구성\n",
    "\n",
    "질문 → WebSearch → LLM 답변 생성 → RAGAS 평가 전체 흐름을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 파이프라인\n",
    "def realtime_rag_evaluation(question: str, reference: str = None) -> dict:\n",
    "    \"\"\"실시간 RAG 평가 파이프라인\n",
    "\n",
    "    Args:\n",
    "        question: 사용자 질문\n",
    "        reference: Ground truth (선택 사항)\n",
    "\n",
    "    Returns:\n",
    "        평가 결과 dict\n",
    "    \"\"\"\n",
    "    # 1. WebSearch로 컨텍스트 수집\n",
    "    contexts = search_with_fallback(question, max_results=3)\n",
    "\n",
    "    if not contexts:\n",
    "        return {\"error\": \"검색 실패\"}\n",
    "\n",
    "    # 2. LLM으로 답변 생성\n",
    "    context_text = \"\\n\\n\".join([f\"[Context {i + 1}]\\n{ctx}\" for i, ctx in enumerate(contexts)])\n",
    "\n",
    "    prompt = f\"\"\"다음 컨텍스트를 참고하여 질문에 답변하세요.\n",
    "컨텍스트에 없는 정보는 사용하지 마세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context_text}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    answer = response.content\n",
    "\n",
    "    # 3. RAGAS 평가\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=question,\n",
    "        response=answer,\n",
    "        retrieved_contexts=contexts,\n",
    "        reference=reference,\n",
    "    )\n",
    "\n",
    "    dataset = EvaluationDataset(samples=[sample])\n",
    "\n",
    "    # reference 유무에 따라 메트릭 선택\n",
    "    # faithfulness, answer_relevancy: reference 불필요\n",
    "    # context_precision, context_recall: reference 필수\n",
    "    if reference:\n",
    "        metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "    else:\n",
    "        metrics = [faithfulness, answer_relevancy]\n",
    "        print(\"reference가 없어 context_precision과 context_recall은 평가하지 않습니다.\")\n",
    "\n",
    "    result = evaluate(\n",
    "        llm=llm,\n",
    "        embeddings=embeddings,\n",
    "        dataset=dataset,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    scores = result.to_pandas().iloc[0]\n",
    "\n",
    "    print(\"RAGAS 점수:\")\n",
    "    print(f\"  - Faithfulness: {scores.get('faithfulness', 0):.3f}\")\n",
    "    print(f\"  - Answer Relevancy: {scores.get('answer_relevancy', 0):.3f}\")\n",
    "    if reference:\n",
    "        print(f\"  - Context Precision: {scores.get('context_precision', 0):.3f}\")\n",
    "        print(f\"  - Context Recall: {scores.get('context_recall', 0):.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"contexts\": contexts,\n",
    "        \"answer\": answer,\n",
    "        \"scores\": {\n",
    "            \"faithfulness\": scores.get(\"faithfulness\", 0),\n",
    "            \"answer_relevancy\": scores.get(\"answer_relevancy\", 0),\n",
    "            \"context_precision\": scores.get(\"context_precision\", 0) if reference else None,\n",
    "            \"context_recall\": scores.get(\"context_recall\", 0) if reference else None,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference가 없어 context_precision과 context_recall은 평가하지 않습니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90afeb246eb04b508c3bfebaac0bbc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bc18a4db3c430fad3e4c417cf243a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d09d8cb18f4c109c10bcc398ce2f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGAS 점수:\n",
      "  - Faithfulness: 1.000\n",
      "  - Answer Relevancy: 0.519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'RAGAS 평가 프레임워크의 핵심 지표는 무엇인가요?',\n",
       " 'contexts': ['query', 'follow_up_questions', 'answer'],\n",
       " 'answer': 'RAGAS 평가 프레임워크의 핵심 지표는 컨텍스트에 없습니다.',\n",
       " 'scores': {'faithfulness': np.float64(1.0),\n",
       "  'answer_relevancy': np.float64(0.5191700890364574),\n",
       "  'context_precision': None,\n",
       "  'context_recall': None}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트: 실시간 평가 실행\n",
    "test_question = \"RAGAS 평가 프레임워크의 핵심 지표는 무엇인가요?\"\n",
    "\n",
    "result = realtime_rag_evaluation(test_question)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS 평가\n",
    "\n",
    "### RAGAS 4대 지표\n",
    "\n",
    "1. Faithfulness (충실성): 답변의 주장이 컨텍스트로 지지되는 비율\n",
    "\n",
    "2. Answer Relevancy (답변 관련성): 답변이 질문에 얼마나 관련 있는가\n",
    "\n",
    "3. Context Precision (컨텍스트 정밀도): 검색된 컨텍스트 중 관련 있는 비율\n",
    "\n",
    "4. Context Recall (컨텍스트 재현율): 정답에 필요한 정보가 컨텍스트에 포함된 비율\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'response', 'reference'], len=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAGAS 평가용 데이터 변환\n",
    "ragas_samples = []\n",
    "for item in sample_data:\n",
    "    contexts = normalize_contexts(item.get(\"contexts\", []))\n",
    "    ragas_samples.append(\n",
    "        SingleTurnSample(\n",
    "            user_input=item[\"question\"],\n",
    "            response=item.get(\"answer\", \"\"),\n",
    "            retrieved_contexts=contexts,\n",
    "            reference=item.get(\"ground_truth\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "ragas_dataset = EvaluationDataset(samples=ragas_samples)\n",
    "ragas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1f1c21ab5f46fba74173421c36452b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fc3eb193694373b9646ed27695ba03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9eda1b2354647ccb7ba049f71cfc7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d57191b56c40a391095603658ad3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28847e9fc6d4f9ab106ff0c95a7d313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b1ab74541547bfad798290d6ab0509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9bb4d658634ecb8fb7a525bf442bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - faithfulness: 0.583\n",
      "  - answer_relevancy: 0.743\n",
      "  - context_precision: 1.000\n",
      "  - context_recall: 0.667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAG 시스템에서 Retriever의 역할은 무엇인가요?</td>\n",
       "      <td>[RAG 시스템의 Retriever 컴포넌트는 질문과 관련된 문서를 벡터 DB에서 ...</td>\n",
       "      <td>Retriever는 벡터 데이터베이스에서 질문과 관련된 문서를 검색하여 제공하는 컴...</td>\n",
       "      <td>Retriever는 사용자의 질문에 관련된 문서를 벡터 데이터베이스에서 검색하여 가...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.788313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LangChain의 주요 장점은 무엇인가요?</td>\n",
       "      <td>[LangChain은 여러 LLM 프로바이더를 통합하여 사용할 수 있는 프레임워크입...</td>\n",
       "      <td>LangChain의 주요 장점은 다양한 LLM과 도구들을 손쉽게 연결하고 체인으로 ...</td>\n",
       "      <td>LangChain은 LLM 애플리케이션 개발을 위한 통합 프레임워크로, 다양한 LL...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embedding 모델의 차원은 무엇을 의미하나요?</td>\n",
       "      <td>[Embedding 차원이 높으면 더 세밀한 의미를 표현할 수 있습니다., Open...</td>\n",
       "      <td>차원은 벡터의 크기를 나타내며, 높을수록 의미를 더 정밀하게 표현하지만 메모리와 계...</td>\n",
       "      <td>Embedding 차원은 텍스트를 벡터로 변환할 때의 벡터 크기를 의미하며, 일반적...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_input  \\\n",
       "0  RAG 시스템에서 Retriever의 역할은 무엇인가요?   \n",
       "1         LangChain의 주요 장점은 무엇인가요?   \n",
       "2     Embedding 모델의 차원은 무엇을 의미하나요?   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [RAG 시스템의 Retriever 컴포넌트는 질문과 관련된 문서를 벡터 DB에서 ...   \n",
       "1  [LangChain은 여러 LLM 프로바이더를 통합하여 사용할 수 있는 프레임워크입...   \n",
       "2  [Embedding 차원이 높으면 더 세밀한 의미를 표현할 수 있습니다., Open...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Retriever는 벡터 데이터베이스에서 질문과 관련된 문서를 검색하여 제공하는 컴...   \n",
       "1  LangChain의 주요 장점은 다양한 LLM과 도구들을 손쉽게 연결하고 체인으로 ...   \n",
       "2  차원은 벡터의 크기를 나타내며, 높을수록 의미를 더 정밀하게 표현하지만 메모리와 계...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  Retriever는 사용자의 질문에 관련된 문서를 벡터 데이터베이스에서 검색하여 가...          1.00   \n",
       "1  LangChain은 LLM 애플리케이션 개발을 위한 통합 프레임워크로, 다양한 LL...          0.50   \n",
       "2  Embedding 차원은 텍스트를 벡터로 변환할 때의 벡터 크기를 의미하며, 일반적...          0.25   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  \n",
       "0          0.788313                1.0             1.0  \n",
       "1          0.999999                1.0             1.0  \n",
       "2          0.441039                1.0             0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAGAS 평가 실행\n",
    "ragas_metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "]\n",
    "\n",
    "ragas_result = evaluate(\n",
    "    llm=llm,\n",
    "    embeddings=embeddings,\n",
    "    dataset=ragas_dataset,\n",
    "    metrics=ragas_metrics,\n",
    ")\n",
    "\n",
    "# 집계 점수 출력\n",
    "ragas_df = ragas_result.to_pandas()\n",
    "\n",
    "for metric_name in [\"faithfulness\", \"answer_relevancy\", \"context_precision\", \"context_recall\"]:\n",
    "    if metric_name in ragas_df.columns:\n",
    "        avg_score = ragas_df[metric_name].mean()\n",
    "        print(f\"  - {metric_name}: {avg_score:.3f}\")\n",
    "\n",
    "ragas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ragas_faithfulness</th>\n",
       "      <th>ragas_relevancy</th>\n",
       "      <th>ragas_ctx_precision</th>\n",
       "      <th>ragas_ctx_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAG 시스템에서 Retriever의 역할은 무엇인가요?...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.788313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LangChain의 주요 장점은 무엇인가요?...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embedding 모델의 차원은 무엇을 의미하나요?...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question  ragas_faithfulness  ragas_relevancy  \\\n",
       "0  RAG 시스템에서 Retriever의 역할은 무엇인가요?...                1.00         0.788313   \n",
       "1         LangChain의 주요 장점은 무엇인가요?...                0.50         0.999999   \n",
       "2     Embedding 모델의 차원은 무엇을 의미하나요?...                0.25         0.441039   \n",
       "\n",
       "   ragas_ctx_precision  ragas_ctx_recall  \n",
       "0                  1.0               1.0  \n",
       "1                  1.0               1.0  \n",
       "2                  1.0               0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 통합\n",
    "comparison_data = []\n",
    "for i, item in enumerate(sample_data):\n",
    "    row = {\n",
    "        \"question\": item[\"question\"][:50] + \"...\",\n",
    "        \"ragas_faithfulness\": ragas_df.iloc[i].get(\"faithfulness\", 0),\n",
    "        \"ragas_relevancy\": ragas_df.iloc[i].get(\"answer_relevancy\", 0),\n",
    "        \"ragas_ctx_precision\": ragas_df.iloc[i].get(\"context_precision\", 0),\n",
    "        \"ragas_ctx_recall\": ragas_df.iloc[i].get(\"context_recall\", 0),\n",
    "    }\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ragas_faithfulness</th>\n",
       "      <th>ragas_relevancy</th>\n",
       "      <th>ragas_ctx_precision</th>\n",
       "      <th>ragas_ctx_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.743117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.381881</td>\n",
       "      <td>0.282208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.614676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.788313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.894156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ragas_faithfulness  ragas_relevancy  ragas_ctx_precision  \\\n",
       "count            3.000000         3.000000                  3.0   \n",
       "mean             0.583333         0.743117                  1.0   \n",
       "std              0.381881         0.282208                  0.0   \n",
       "min              0.250000         0.441039                  1.0   \n",
       "25%              0.375000         0.614676                  1.0   \n",
       "50%              0.500000         0.788313                  1.0   \n",
       "75%              0.750000         0.894156                  1.0   \n",
       "max              1.000000         0.999999                  1.0   \n",
       "\n",
       "       ragas_ctx_recall  \n",
       "count          3.000000  \n",
       "mean           0.666667  \n",
       "std            0.577350  \n",
       "min            0.000000  \n",
       "25%            0.500000  \n",
       "50%            1.000000  \n",
       "75%            1.000000  \n",
       "max            1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 통계\n",
    "comparison_df[\n",
    "    [\n",
    "        \"ragas_faithfulness\",\n",
    "        \"ragas_relevancy\",\n",
    "        \"ragas_ctx_precision\",\n",
    "        \"ragas_ctx_recall\",\n",
    "    ]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특이 케이스 분석\n",
    "\n",
    "두 평가 방법 간의 불일치를 통해 개선 방향을 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ragas_faithfulness</th>\n",
       "      <th>ragas_relevancy</th>\n",
       "      <th>ragas_ctx_precision</th>\n",
       "      <th>ragas_ctx_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embedding 모델의 차원은 무엇을 의미하나요?...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          question  ragas_faithfulness  ragas_relevancy  \\\n",
       "2  Embedding 모델의 차원은 무엇을 의미하나요?...                0.25         0.441039   \n",
       "\n",
       "   ragas_ctx_precision  ragas_ctx_recall  \n",
       "2                  1.0               0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 케이스 1: Faithfulness 낮음\n",
    "# → 의미적으로 유사하지만 컨텍스트 근거 부족 (잠재적 환각)\n",
    "\n",
    "median_faith = comparison_df[\"ragas_faithfulness\"].median()\n",
    "\n",
    "low_faith = comparison_df[(comparison_df[\"ragas_faithfulness\"] < median_faith)]\n",
    "\n",
    "low_faith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ragas_faithfulness</th>\n",
       "      <th>ragas_relevancy</th>\n",
       "      <th>ragas_ctx_precision</th>\n",
       "      <th>ragas_ctx_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAG 시스템에서 Retriever의 역할은 무엇인가요?...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.788313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LangChain의 주요 장점은 무엇인가요?...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question  ragas_faithfulness  ragas_relevancy  \\\n",
       "0  RAG 시스템에서 Retriever의 역할은 무엇인가요?...                 1.0         0.788313   \n",
       "1         LangChain의 주요 장점은 무엇인가요?...                 0.5         0.999999   \n",
       "\n",
       "   ragas_ctx_precision  ragas_ctx_recall  \n",
       "0                  1.0               1.0  \n",
       "1                  1.0               1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 케이스 2: Relevancy 높음\n",
    "# → 질문에 관련성 높지만 표현이 다름 (패러프레이즈)\n",
    "\n",
    "median_rel = comparison_df[\"ragas_relevancy\"].median()\n",
    "\n",
    "high_rel = comparison_df[(comparison_df[\"ragas_relevancy\"] >= median_rel)]\n",
    "\n",
    "high_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RAGAS 종합 평가 결과 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAGAS 평균 점수:\n",
      "  - Faithfulness: 0.583\n",
      "  - Relevancy: 0.743\n",
      "  - Context Precision: 1.000\n",
      "  - Context Recall: 0.667\n",
      "\n",
      "해석:\n",
      "낮은 충실성: 컨텍스트 근거 부족 또는 환각 위험\n",
      "→ 프롬프트 개선, LLM 온도 낮추기, Guardrails 적용\n",
      "낮은 Context Recall: 검색 실패 (필요 정보 누락)\n",
      "→ top_k 증가, Hybrid 검색 (벡터 + BM25), 리트리버 성능 평가\n"
     ]
    }
   ],
   "source": [
    "# RAGAS 종합 평가\n",
    "avg_faith_val = comparison_df[\"ragas_faithfulness\"].mean()\n",
    "avg_rel_val = comparison_df[\"ragas_relevancy\"].mean()\n",
    "avg_ctx_p = comparison_df[\"ragas_ctx_precision\"].mean()\n",
    "avg_ctx_r = comparison_df[\"ragas_ctx_recall\"].mean()\n",
    "\n",
    "print(\"\\nRAGAS 평균 점수:\")\n",
    "print(f\"  - Faithfulness: {avg_faith_val:.3f}\")\n",
    "print(f\"  - Relevancy: {avg_rel_val:.3f}\")\n",
    "print(f\"  - Context Precision: {avg_ctx_p:.3f}\")\n",
    "print(f\"  - Context Recall: {avg_ctx_r:.3f}\")\n",
    "\n",
    "\n",
    "# 항상 이러한 점수가 기준인 것은 아닙니다.\n",
    "if avg_faith_val >= 0.8:\n",
    "    print(\"높은 충실성 + 높은 유사도: 전반적으로 양호한 품질\")\n",
    "elif avg_faith_val < 0.7:\n",
    "    print(\"낮은 충실성: 컨텍스트 근거 부족 또는 환각 위험\")\n",
    "    print(\"→ 프롬프트 개선, LLM 온도 낮추기, Guardrails 적용\")\n",
    "\n",
    "if avg_ctx_r < 0.7:\n",
    "    print(\"낮은 Context Recall: 검색 실패 (필요 정보 누락)\")\n",
    "    print(\"→ top_k 증가, Hybrid 검색 (벡터 + BM25), 리트리버 성능 평가\")\n",
    "\n",
    "if avg_ctx_p < 0.7:\n",
    "    print(\"낮은 Context Precision: 무관 문서 검색 (노이즈)\")\n",
    "    print(\"→ 리랭커 추가, 청킹 전략 재설계, 임베딩 모델 파인튜닝\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
