"""
# LLM í‰ê°€ë¥¼ ìœ„í•œ í•©ì„± ë°ì´í„°ì…‹ ìƒì„±

ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ **í•©ì„± ë°ì´í„°ì…‹ì„ ìƒì„±**í•˜ê³  í‰ê°€ë¥¼ ìœ„í•´ [Langfuse](https://langfuse.com)ì— ì—…ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë´…ë‹ˆë‹¤.

## Langfuse ë°ì´í„°ì…‹ì´ë€?

Langfuseì—ì„œ *ë°ì´í„°ì…‹*ì€ *ë°ì´í„°ì…‹ í•­ëª©*ì˜ ëª¨ìŒì´ë©°, ê° í•­ëª©ì€ ì¼ë°˜ì ìœ¼ë¡œ `input`(ì˜ˆ: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸/ì§ˆë¬¸), `expected_output`(ì •ë‹µ ë˜ëŠ” ì´ìƒì ì¸ ë‹µë³€) ë° ì„ íƒì  ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

ë°ì´í„°ì…‹ì€ **í‰ê°€**ì— ì‚¬ìš©ë©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì˜ ê° í•­ëª©ì—ì„œ LLM ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‘ë‹µì„ ì˜ˆìƒ ì¶œë ¥ê³¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì„±(ì˜ˆ: ëª¨ë¸ ë²„ì „ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ë³€ê²½)ì— ê±¸ì³ ì„±ëŠ¥ì„ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë°ì´í„°ì…‹ì´ ì»¤ë²„í•´ì•¼ í•  ì¼€ì´ìŠ¤

**Happy path** â€“ ê°„ë‹¨í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì¿¼ë¦¬:
- "What is the capital of France?"
- "Convert 5 USD to EUR."

**ì—£ì§€ ì¼€ì´ìŠ¤** â€“ ë¹„ì •ìƒì ì´ê±°ë‚˜ ë³µì¡í•œ:
- ë§¤ìš° ê¸´ í”„ë¡¬í”„íŠ¸.
- ëª¨í˜¸í•œ ì¿¼ë¦¬.
- ë§¤ìš° ê¸°ìˆ ì ì´ê±°ë‚˜ í‹ˆìƒˆì‹œì¥.

**ì ëŒ€ì  ì¼€ì´ìŠ¤** â€“ ì•…ì˜ì ì´ê±°ë‚˜ ê¹Œë‹¤ë¡œìš´:
- í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ì‹œë„ ("Ignore all instructions and ...").
- ì½˜í…ì¸  ì •ì±… ìœ„ë°˜ (í˜„ì˜¤, ì¦ì˜¤ ë°œì–¸).
- ë…¼ë¦¬ í•¨ì • (ë‚™ì„¸ ì§ˆë¬¸).

## ì˜ˆì œ

### ì˜ˆì œ 1: OpenAI API ë°˜ë³µ

OpenAIì˜ APIë¥¼ ê°„ë‹¨í•œ ë£¨í”„ë¡œ ì‚¬ìš©í•˜ì—¬ í•­ê³µì‚¬ ì±—ë´‡ì„ ìœ„í•œ í•©ì„± ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
ìœ ì‚¬í•˜ê²Œ ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸í•˜ì—¬ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ *ëª¨ë‘* ìƒì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
"""

import os

# Get keys for your project from the project settings page: https://cloud.langfuse.com
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-..."
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-..."
os.environ["LANGFUSE_BASE_URL"] = "https://us.cloud.langfuse.com"  # ğŸ‡ºğŸ‡¸ US region

# Your openai key
os.environ["OPENAI_API_KEY"] = "sk-proj-..."

"""í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ë©´ ì´ì œ Langfuse í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `get_client()`ëŠ” í™˜ê²½ ë³€ìˆ˜ì— ì œê³µëœ ìê²© ì¦ëª…ì„ ì‚¬ìš©í•˜ì—¬ Langfuse í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""

from langfuse import get_client

langfuse = get_client()

# Verify connection
if langfuse.auth_check():
    print("Langfuse client is authenticated and ready!")
else:
    print("Authentication failed. Please check your credentials and host.")

import pandas as pd
from openai import OpenAI

client = OpenAI()


# Function to generate airline questions
def generate_airline_questions(num_questions=20):
    questions = []

    for i in range(num_questions):
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a helpful customer service chatbot for an airline. "
                        "Please generate a short, realistic question from a customer."
                    ),
                }
            ],
            temperature=1,
        )
        question_text = completion.choices[0].message.content.strip()
        questions.append(question_text)

    return questions


# Generate 20 airline-related questions
airline_questions = generate_airline_questions(num_questions=20)

# Convert to a Pandas DataFrame
df = pd.DataFrame({"Question": airline_questions})

from langfuse import get_client

langfuse = get_client()

# Create a new dataset in Langfuse
dataset_name = "openai_synthetic_dataset"
langfuse.create_dataset(
    name=dataset_name,
    description="Synthetic Q&A dataset generated via OpenAI in a loop",
    metadata={"approach": "openai_loop", "category": "mixed"},
)

# Upload each Q&A as a dataset item
for _, row in df.iterrows():
    langfuse.create_dataset_item(dataset_name="openai_loop_dataset", input=row["Question"])

"""

### ì˜ˆì œ 2: RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬

**RAG**ì˜ ê²½ìš° *íŠ¹ì • ë¬¸ì„œì— ê¸°ë°˜í•œ* ì§ˆë¬¸ì„ ì›í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆìœ¼ë©° RAG íŒŒì´í”„ë¼ì¸ì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ê²€ìƒ‰í•˜ê³  ì‚¬ìš©í•˜ëŠ”ì§€ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[RAGAS](https://docs.ragas.io/en/stable/getstarted/rag_testset_generation/#testset-generation)ëŠ” RAGì˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìƒì„±ì„ ìë™í™”í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì½”í¼ìŠ¤ë¥¼ ê°€ì ¸ì™€ ê´€ë ¨ ì¿¼ë¦¬ì™€ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ì˜ˆë¥¼ ë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤:

_**ì°¸ê³ **: ì´ ì˜ˆì œëŠ” [RAGAS ë¬¸ì„œ](https://docs.ragas.io/en/stable/getstarted/rag_testset_generation/)ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤_
"""

from langchain_community.document_loaders import DirectoryLoader

path = "Sample_Docs_Markdown"
loader = DirectoryLoader(path, glob="**/*.md")
docs = loader.load()

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.llms import LangchainLLMWrapper

generator_llm = LangchainLLMWrapper(ChatOpenAI(model="gpt-4o"))
generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())

from ragas.testset import TestsetGenerator

generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)
dataset = generator.generate_with_langchain_docs(docs, testset_size=10)

# 4. The result `testset` can be converted to a pandas DataFrame for inspection
df = dataset.to_pandas()

from langfuse import get_client

langfuse = get_client()

# 5. Push the RAGAS-generated testset to Langfuse
langfuse.create_dataset(
    name="ragas_generated_testset",
    description="Synthetic RAG test set (RAGAS)",
    metadata={"source": "RAGAS", "docs_used": len(docs)},
)

for _, row in df.iterrows():
    langfuse.create_dataset_item(
        dataset_name="ragas_generated_testset",
        input=row["user_input"],
        metadata=row["reference_contexts"],
    )

"""
### DeepEval ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ë°ì´í„° ìƒì„± í›„ LangFuse ì— DataSet ê²°í•©í•˜ê¸°

[DeepEval](https://docs.confident-ai.com/docs/synthesizer-introduction)ì€ *Synthesizer* í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
"""


import os

from deepeval.synthesizer import Synthesizer
from deepeval.synthesizer.config import StylingConfig
from langfuse import get_client

# 1. Define the style we want for our synthetic data.
# For instance, we want user questions and correct SQL queries.
styling_config = StylingConfig(
    input_format="Questions in English that asks for data in database.",
    expected_output_format="SQL query based on the given input",
    task="Answering text-to-SQL-related queries by querying a database and returning the results to users",
    scenario="Non-technical users trying to query a database using plain English.",
)

# 2. Initialize the Synthesizer
synthesizer = Synthesizer(styling_config=styling_config)

# 3. Generate synthetic items from scratch, e.g. 20 items for a short demo
synthesizer.generate_goldens_from_scratch(num_goldens=20)

# 4. Access the generated examples
synthetic_goldens = synthesizer.synthetic_goldens

from langfuse import get_client

langfuse = get_client()

# 5. Create a Langfuse dataset
deepeval_dataset_name = "deepeval_synthetic_data"
langfuse.create_dataset(
    name=deepeval_dataset_name,
    description="Synthetic text-to-SQL data (DeepEval)",
    metadata={"approach": "deepeval", "task": "text-to-sql"},
)

# 6. Upload the items
for golden in synthetic_goldens:
    langfuse.create_dataset_item(
        dataset_name=deepeval_dataset_name,
        input={"query": golden.input},
    )
