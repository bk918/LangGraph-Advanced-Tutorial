{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from openrouter_llm import create_embedding_model, create_openrouter_llm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = create_openrouter_llm(model=\"gpt-4.1\", temperature=0.3)\n",
    "embeddings = create_embedding_model(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Persona ì •ì˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7ê°œ Persona ë¡œë“œ ì™„ë£Œ:\n",
      "\n",
      "  - Junior Developer: ì‹ ì… ë˜ëŠ” ê²½ë ¥ 1-2ë…„ì°¨ ê°œë°œì. ê¸°ë³¸ì ì¸ ê¸°ìˆ  ì§€ì‹ì€ ìˆì§€ë§Œ ì‹¤ë¬´ ê²½í—˜ì´ ë¶€ì¡±í•˜ì—¬ ìì„¸í•œ ê°€ì´ë“œê°€ í•„ìš”í•¨...\n",
      "  - Senior Engineer: ê²½ë ¥ 5ë…„ ì´ìƒì˜ ìˆ™ë ¨ëœ ì—”ì§€ë‹ˆì–´. ê¹Šì€ ê¸°ìˆ  ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©° ê°„ê²°í•˜ê³  íš¨ìœ¨ì ì¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ì„ í˜¸í•¨...\n",
      "  - Non-Technical Manager: ê¸°ìˆ  ë°°ê²½ì´ ì—†ëŠ” íŒ€ì¥/ê´€ë¦¬ì. ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„ì™€ ê²°ê³¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‚¬ê³ í•˜ë©° ì‰¬ìš´ ì„¤ëª…ì„ í•„ìš”ë¡œ í•¨...\n",
      "  - New Employee: íšŒì‚¬ì— ì²˜ìŒ ì…ì‚¬í•œ ì‹ ì… ì§ì›. íšŒì‚¬ ì‹œìŠ¤í…œê³¼ í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•œ ì§€ì‹ì´ ì „ë¬´í•˜ì—¬ ê¸°ë³¸ì ì¸ ê²ƒë¶€í„° ì§ˆë¬¸í•¨...\n",
      "  - Power User: ì‹œìŠ¤í…œê³¼ ë„êµ¬ë¥¼ ëŠ¥ìˆ™í•˜ê²Œ ì‚¬ìš©í•˜ëŠ” ì¤‘ê¸‰ ì´ìƒ ì‚¬ìš©ì. íš¨ìœ¨ì„±ê³¼ ìë™í™”ì— ê´€ì‹¬ì´ ë§ìœ¼ë©° ê³ ê¸‰ ê¸°ëŠ¥ì„ ì ê·¹ì ìœ¼ë¡œ...\n",
      "  - Remote Worker: ì¬íƒê·¼ë¬´ë‚˜ ì›ê²©ì§€ì—ì„œ ê·¼ë¬´í•˜ëŠ” ì§ì›. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ê³¼ ì›ê²© ì ‘ì† ê´€ë ¨ ì´ìŠˆê°€ ë§ìœ¼ë©° ì¦‰ê°ì ì¸ í•´ê²°ì´ í•„ìš”í•¨...\n",
      "  - Security-Conscious User: ë³´ì•ˆê³¼ ê°œì¸ì •ë³´ ë³´í˜¸ì— ë¯¼ê°í•œ ì‚¬ìš©ì. ëª¨ë“  ì‘ì—…ì—ì„œ ë³´ì•ˆ ì˜í–¥ë„ë¥¼ ê³ ë ¤í•˜ë©° ê·œì • ì¤€ìˆ˜ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•¨...\n"
     ]
    }
   ],
   "source": [
    "# Persona ì •ì˜ ë¡œë“œ\n",
    "persona_path = Path(\"persona_definitions.yaml\")\n",
    "\n",
    "with persona_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    persona_config = yaml.safe_load(f)\n",
    "\n",
    "personas = persona_config[\"personas\"]\n",
    "\n",
    "print(f\"{len(personas)}ê°œ Persona ë¡œë“œ ì™„ë£Œ:\\n\")\n",
    "for p in personas:\n",
    "    print(f\"  - {p['name']}: {p['role_description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Personaë³„ ì§ˆë¬¸ ìƒì„±\n",
    "\n",
    "ê° Personaì˜ íŠ¹ì„±ì„ ë°˜ì˜í•œ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "question_generation_template = \"\"\"\n",
    "ë‹¹ì‹ ì€ IT Helpdesk ì‹œìŠ¤í…œì˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ Personaì˜ íŠ¹ì„±ì„ ì •í™•íˆ ë°˜ì˜í•˜ì—¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”:\n",
    "\n",
    "**Persona**: {persona_name}\n",
    "**ì—­í• **: {role_description}\n",
    "**ì „ë¬¸ì„± ìˆ˜ì¤€**: {expertise_level}\n",
    "**ê¸°ìˆ  ê¹Šì´**: {technical_depth}\n",
    "\n",
    "**í–‰ë™ íŒ¨í„´**:\n",
    "{behaviors}\n",
    "\n",
    "**ì§ˆë¬¸ íŒ¨í„´ ì˜ˆì‹œ**:\n",
    "{question_patterns}\n",
    "\n",
    "**ê¸°ì¡´ ì§ˆë¬¸ ì˜ˆì‹œ**:\n",
    "{example_questions}\n",
    "\n",
    "ìœ„ Personaì˜ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ IT Helpdesk ê´€ë ¨ ì§ˆë¬¸ì„ **{num_questions}ê°œ** ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì¡°ê±´:\n",
    "1. ê° ì§ˆë¬¸ì€ Personaì˜ í–‰ë™ íŒ¨í„´ê³¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼ì„ ëª…í™•íˆ ë°˜ì˜\n",
    "2. ì§ˆë¬¸ ê°„ ì¤‘ë³µ ìµœì†Œí™” (ë‹¤ì–‘í•œ ì£¼ì œ)\n",
    "3. ì‹¤ì œ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë²•í•œ í˜„ì‹¤ì ì¸ ì§ˆë¬¸\n",
    "4. ì§ˆë¬¸ë§Œ ìƒì„± (ë‹µë³€ ë¶ˆí•„ìš”)\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹: JSON ë°°ì—´\n",
    "```json\n",
    "[\n",
    "  {{\"question\": \"ì§ˆë¬¸ 1\"}},\n",
    "  {{\"question\": \"ì§ˆë¬¸ 2\"}},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "question_prompt = ChatPromptTemplate.from_template(question_generation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personaë³„ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜\n",
    "def generate_questions_for_persona(persona: Dict, num_questions: int = 20) -> List[str]:\n",
    "    \"\"\"íŠ¹ì • Personaì— ë§ëŠ” ì§ˆë¬¸ ìƒì„±\"\"\"\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    behaviors_text = \"\\n\".join([f\"- {b}\" for b in persona[\"behaviors\"]])\n",
    "    patterns_text = \"\\n\".join([f\"- {p}\" for p in persona[\"question_patterns\"]])\n",
    "    examples_text = \"\\n\".join([f\"- {e}\" for e in persona[\"example_questions\"]])\n",
    "\n",
    "    messages = question_prompt.format_messages(\n",
    "        persona_name=persona[\"name\"],\n",
    "        role_description=persona[\"role_description\"],\n",
    "        expertise_level=persona[\"characteristics\"][\"expertise_level\"],\n",
    "        technical_depth=persona[\"characteristics\"][\"technical_depth\"],\n",
    "        behaviors=behaviors_text,\n",
    "        question_patterns=patterns_text,\n",
    "        example_questions=examples_text,\n",
    "        num_questions=num_questions,\n",
    "    )\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # JSON íŒŒì‹±\n",
    "    try:\n",
    "        # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (```json ... ``` í˜•ì‹ ì²˜ë¦¬)\n",
    "        content = response.content\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "\n",
    "        questions_data = json.loads(content.strip())\n",
    "        questions = [q[\"question\"] for q in questions_data]\n",
    "        return questions\n",
    "    except Exception as e:\n",
    "        print(f\"JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "        print(f\"ì‘ë‹µ ë‚´ìš©: {response.content[:200]}...\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Junior Developer...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[2/7] Senior Engineer...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[3/7] Non-Technical Manager...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[4/7] New Employee...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[5/7] Power User...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[6/7] Remote Worker...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[7/7] Security-Conscious User...\n",
      "20ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "\n",
      "ì „ì²´ 140ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë“  Personaì— ëŒ€í•´ ì§ˆë¬¸ ìƒì„±\n",
    "all_persona_questions = {}\n",
    "\n",
    "for i, persona in enumerate(personas):\n",
    "    persona_name = persona[\"name\"]\n",
    "    print(f\"[{i + 1}/{len(personas)}] {persona_name}...\")\n",
    "\n",
    "    questions = generate_questions_for_persona(persona, num_questions=20)\n",
    "    all_persona_questions[persona_name] = questions\n",
    "\n",
    "    print(f\"{len(questions)}ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\\n\")\n",
    "\n",
    "total_questions = sum(len(qs) for qs in all_persona_questions.values())\n",
    "print(f\"\\nì „ì²´ {total_questions}ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¤ì–‘ì„± ë¶„ì„\n",
    "\n",
    "Persona ê°„ ì§ˆë¬¸ ë‹¤ì–‘ì„±ì„ ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ff78ae66ab479f81d13d3f68f1a82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140ê°œ ì§ˆë¬¸ ì„ë² ë”© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ëª¨ë“  ì§ˆë¬¸ ì„ë² ë”© ìƒì„±\n",
    "all_questions_flat = []\n",
    "question_to_persona = {}\n",
    "\n",
    "for persona_name, questions in all_persona_questions.items():\n",
    "    for q in questions:\n",
    "        all_questions_flat.append(q)\n",
    "        question_to_persona[q] = persona_name\n",
    "\n",
    "# ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±\n",
    "question_embeddings = embeddings.embed_documents(all_questions_flat)\n",
    "\n",
    "print(f\"{len(question_embeddings)}ê°œ ì§ˆë¬¸ ì„ë² ë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Persona ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤:\n",
      "\n",
      "                       Junior Develope   Senior Engineer   Non-Technical M      New Employee        Power User     Remote Worker   Security-Consci\n",
      "Junior Developer                 1.000             0.669             0.750             0.796             0.701             0.758             0.662\n",
      "Senior Engineer                  0.669             1.000             0.633             0.570             0.624             0.668             0.604\n",
      "Non-Technical Manager             0.750             0.633             1.000             0.795             0.767             0.833             0.746\n",
      "New Employee                     0.796             0.570             0.795             1.000             0.734             0.728             0.713\n",
      "Power User                       0.701             0.624             0.767             0.734             1.000             0.694             0.718\n",
      "Remote Worker                    0.758             0.668             0.833             0.728             0.694             1.000             0.665\n",
      "Security-Conscious User             0.662             0.604             0.746             0.713             0.718             0.665             1.000\n"
     ]
    }
   ],
   "source": [
    "# Persona ê°„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°\n",
    "persona_avg_embeddings = {}\n",
    "\n",
    "for persona_name, questions in all_persona_questions.items():\n",
    "    persona_indices = [\n",
    "        i for i, q in enumerate(all_questions_flat) if question_to_persona[q] == persona_name\n",
    "    ]\n",
    "    persona_embs = np.array([question_embeddings[i] for i in persona_indices])\n",
    "    persona_avg_embeddings[persona_name] = persona_embs.mean(axis=0)\n",
    "\n",
    "# Persona ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "persona_names = list(persona_avg_embeddings.keys())\n",
    "persona_emb_matrix = np.array([persona_avg_embeddings[name] for name in persona_names])\n",
    "similarity_matrix = cosine_similarity(persona_emb_matrix)\n",
    "\n",
    "print(\"\\nPersona ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤:\\n\")\n",
    "print(f\"{'':20s}\", end=\"\")\n",
    "for name in persona_names:\n",
    "    print(f\"{name[:15]:>18s}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, name1 in enumerate(persona_names):\n",
    "    print(f\"{name1:20s}\", end=\"\")\n",
    "    for j, name2 in enumerate(persona_names):\n",
    "        print(f\"{similarity_matrix[i][j]:18.3f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë‹¤ì–‘ì„± ë¶„ì„ ê²°ê³¼:\n",
      "  - Persona ê°„ í‰ê·  ìœ ì‚¬ë„: 0.706\n",
      "  - ë‹¤ì–‘ì„± ì ìˆ˜: 0.294\n",
      "\n",
      "í•´ì„:\n",
      "  ì ë‹¹í•œ ë‹¤ì–‘ì„± (ê°œì„  ê°€ëŠ¥)\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì–‘ì„± ì ìˆ˜ (1 - í‰ê·  ìœ ì‚¬ë„)\n",
    "# ëŒ€ê°ì„  ì œì™¸í•œ í‰ê· \n",
    "off_diagonal = []\n",
    "for i in range(len(similarity_matrix)):\n",
    "    for j in range(len(similarity_matrix)):\n",
    "        if i != j:\n",
    "            off_diagonal.append(similarity_matrix[i][j])\n",
    "\n",
    "avg_similarity = np.mean(off_diagonal)\n",
    "diversity_score = 1 - avg_similarity\n",
    "\n",
    "print(\"\\në‹¤ì–‘ì„± ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"  - Persona ê°„ í‰ê·  ìœ ì‚¬ë„: {avg_similarity:.3f}\")\n",
    "print(f\"  - ë‹¤ì–‘ì„± ì ìˆ˜: {diversity_score:.3f}\")\n",
    "print(\"\\ní•´ì„:\")\n",
    "if diversity_score > 0.3:\n",
    "    print(\"  ë§¤ìš° ë‹¤ì–‘í•œ ì§ˆë¬¸ ìƒì„± (ìš°ìˆ˜)\")\n",
    "elif diversity_score > 0.15:\n",
    "    print(\"  ì ë‹¹í•œ ë‹¤ì–‘ì„± (ê°œì„  ê°€ëŠ¥)\")\n",
    "else:\n",
    "    print(\"  ë‚®ì€ ë‹¤ì–‘ì„± (Persona ì •ì˜ ê°œì„  í•„ìš”)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë™ì¼ ì£¼ì œ Personaë³„ ë¹„êµ\n",
    "\n",
    "ë™ì¼í•œ ì£¼ì œ(ì˜ˆ: ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì •)ì— ëŒ€í•œ Personaë³„ ì§ˆë¬¸ ì°¨ì´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 'ë¹„ë°€ë²ˆí˜¸' ê´€ë ¨ Personaë³„ ì§ˆë¬¸:\n",
      "\n",
      "â”â”â” Junior Developer â”â”â”\n",
      "  â€¢ íšŒì‚¬ì—ì„œ ì œê³µí•˜ëŠ” ì›ê²© ë°ìŠ¤í¬í†± ì ‘ì† ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë¶„ì‹¤í–ˆìŠµë‹ˆë‹¤. ë³µêµ¬ ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ì•ˆë‚´í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n",
      "\n",
      "â”â”â” New Employee â”â”â”\n",
      "  â€¢ PC ë¹„ë°€ë²ˆí˜¸ë¥¼ ìŠì–´ë²„ë ¸ëŠ”ë° ì–´ë–»ê²Œ ì´ˆê¸°í™”í•  ìˆ˜ ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ì ˆì°¨ê°€ ì–´ë”” ì•ˆë‚´ë˜ì–´ ìˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”?\n",
      "\n",
      "â”â”â” Remote Worker â”â”â”\n",
      "  â€¢ ì§€ê¸ˆ ì‚¬ë‚´ ê·¸ë£¹ì›¨ì–´ ë¡œê·¸ì¸ ì˜¤ë¥˜ê°€ ë°˜ë³µë©ë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ ë¦¬ì…‹ë„ í•´ë´¤ëŠ”ë° ì•ˆ ë©ë‹ˆë‹¤. ì˜¤ëŠ˜ ì—…ë¬´ì— ê¼­ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "â”â”â” Security-Conscious User â”â”â”\n",
      "  â€¢ ëª¨ë“  ë¹„ë°€ë²ˆí˜¸ëŠ” í•´ì‹œê°’ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ë‚˜ìš”? ì–´ë–¤ í•´ì‹œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ë‚˜ìš”?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì£¼ì œ: ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì •\n",
    "topic_keyword = \"ë¹„ë°€ë²ˆí˜¸\"\n",
    "\n",
    "print(f\"ğŸ” '{topic_keyword}' ê´€ë ¨ Personaë³„ ì§ˆë¬¸:\\n\")\n",
    "\n",
    "for persona_name, questions in all_persona_questions.items():\n",
    "    related_questions = [q for q in questions if topic_keyword in q]\n",
    "    if related_questions:\n",
    "        print(f\"â”â”â” {persona_name} â”â”â”\")\n",
    "        for q in related_questions[:2]:\n",
    "            print(f\"  â€¢ {q}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona ê¸°ë°˜ ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: persona_based_dataset.jsonl\n",
      " ì´ 140ê°œ ë ˆì½”ë“œ\n"
     ]
    }
   ],
   "source": [
    "# JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥\n",
    "output_path = Path(\"persona_based_dataset.jsonl\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for persona_name, questions in all_persona_questions.items():\n",
    "        # Persona ì •ë³´ ì°¾ê¸°\n",
    "        persona_info = next((p for p in personas if p[\"name\"] == persona_name), None)\n",
    "\n",
    "        for question in questions:\n",
    "            record = {\n",
    "                \"question\": question,\n",
    "                \"persona\": persona_name,\n",
    "                \"persona_characteristics\": persona_info[\"characteristics\"] if persona_info else {},\n",
    "                \"expected_behavior\": {\n",
    "                    \"response_style\": persona_info[\"characteristics\"][\"communication_style\"]\n",
    "                    if persona_info\n",
    "                    else \"Unknown\",\n",
    "                    \"detail_level\": persona_info[\"characteristics\"][\"detail_preference\"]\n",
    "                    if persona_info\n",
    "                    else \"Unknown\",\n",
    "                },\n",
    "                \"metadata\": {\"source\": \"persona_generator\", \"topic\": \"IT_Helpdesk\"},\n",
    "            }\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Persona ê¸°ë°˜ ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "print(f\" ì´ {len(all_questions_flat)}ê°œ ë ˆì½”ë“œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
